# FD-LLM Demo Project - Complete Summary

## Project Overview

**FD-LLM** is a hybrid fault detection and explanation system for slurry pipeline monitoring that combines:
- **MultiROCKET Classifier** (fast time-series pattern recognition)
- **Mistral-7B LLM** (natural language explanations with self-consistency)

**Status:** âœ… **Complete Demo/Prototype**

### ğŸ¬ Quick Demo

```bash
conda activate rm
python demo.py
```

See the system in action with pre-trained models and LLM explanations!

---

## What We Built

### 1. Data Pipeline âœ…
- CSV loading with flexible timestamp parsing
- 60-second windowing with 15-second stride
- Feature extraction (flow, density, pressure statistics)
- Physical validation (mass balance, density-SG checks)

**Files:**
- `data/loaders/slurry_loader.py`
- `models/encoders/feature_extractor.py`
- `utils/physical_checks.py`

### 2. MultiROCKET Classifier âœ…
- Time-series classifier trained on sensor data
- **Current Performance:** 75% accuracy
- Detects: Dilution, Normal, Settling/Segregation
- Fast inference (~milliseconds per window)

**Files:**
- `models/rocket_heads.py`
- `training/train_rocket.py`
- `outputs/exp_full_dataset/model.pkl`

**Results:**
```
Overall Accuracy: 75%
Macro F1: 0.66

Prediction Distribution (5,236 windows):
  Dilution: 2,625 (50.1%)
  Normal: 1,800 (34.4%)
  Settling/Segregation: 811 (15.5%)
```

### 3. LLM Explainer âœ…
- Mistral-7B-Instruct with 4-bit quantization
- Generates structured JSON explanations with:
  - Fault diagnosis
  - Numeric evidence from sensor data
  - Physical consistency cross-checks
  - Recommended actions
- Self-consistency voting (k=5 explanations, majority vote)

**Files:**
- `explainer/llm_setup.py`
- `explainer/prompt_templates.py`
- `explainer/self_consistency.py`
- `FD_LLM_Colab_Explainer.ipynb`

**Example Output:**
```json
{
  "final_diagnosis": "Dilution",
  "confidence": 0.856,
  "evidence": [
    "Density Mean is 1009.6 kg/mÂ³, below normal range of 1015 kg/mÂ³",
    "Density trending downward at -65.00 kg/mÂ³ per 5min",
    "SG at 1.010 is 0.020 below target, confirming water addition"
  ],
  "cross_checks": [
    "Check for potential upstream influencing factors on flow and density",
    "Inspect slurry composition and potential dilution sources"
  ],
  "recommended_actions": [
    "Monitor and adjust slurry composition to maintain process variables within normal range",
    "Investigate upstream water injection systems"
  ]
}
```

### 4. Analysis & Utilities âœ…
- Filter scripts for fault-only and high-confidence predictions
- Performance analysis tools
- Colab notebook for GPU-accelerated explanation generation

**Files:**
- `filter_fault_windows.py`
- `filter_high_confidence_faults.py`
- `analyze_classifier_performance.py`
- `export_for_colab.py`

---

## Current Dataset Statistics

**Input Data:** `data_4b0c_250926-0000_250926-2251.csv`

**Characteristics:**
- Time period: 09/26/2025, 00:00 - 22:51 (22 hours 51 minutes)
- Total windows: 5,236
- Fault rate: 65.6% (abnormally high - likely stress test or maintenance period)
- Temporal pattern: Mostly faults except windows 1000-1500 (normal period)

**Filtered Datasets Available:**
1. **All faults:** 3,436 windows (removes Normal)
2. **High-confidence faults:** 2,403 windows (confidence â‰¥0.7)

---

## Demo Capabilities

### What This System Can Do:

âœ… **Real-time fault detection** (classifier runs in milliseconds)  
âœ… **Natural language explanations** for detected faults  
âœ… **Evidence-based reasoning** with numeric claims from actual sensor data  
âœ… **Self-consistency validation** (multiple explanation attempts with voting)  
âœ… **Actionable recommendations** for operators  
âœ… **Scalable architecture** (classifier local, LLM on cloud GPU)  

### Current Limitations:

âš ï¸ **Classifier accuracy is 75%** (production systems need â‰¥90%)  
âš ï¸ **Training data from abnormal period** (65% fault rate vs expected 5-15%)  
âš ï¸ **LLM explanations not fine-tuned** (using pre-trained Mistral, not domain-adapted)  
âš ï¸ **Label quality uncertain** (heuristic-based, not expert-verified)  

---

## Key Files & Outputs

### Trained Models
```
outputs/exp_full_dataset/
â”œâ”€â”€ model.pkl              # Trained MultiROCKET classifier
â”œâ”€â”€ results.json           # Training metrics
â”œâ”€â”€ confusion_matrix.png   # Performance visualization
â””â”€â”€ classification_report.txt
```

### Prediction Datasets
```
outputs/exp_full_dataset/
â”œâ”€â”€ predictions_for_colab.parquet           # All 5,236 windows
â”œâ”€â”€ predictions_faults_only.parquet         # 3,436 fault windows
â””â”€â”€ predictions_high_conf_faults.parquet    # 2,403 high-confidence faults
```

### Explanations (if generated)
```
outputs/exp_full_dataset/
â””â”€â”€ explanations.jsonl     # LLM-generated explanations
```

### Notebooks
```
FD_LLM_Colab_Explainer.ipynb   # GPU-accelerated explanation generation
```

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RAW SENSOR DATA                         â”‚
â”‚              (CSV with timestamps + 11 sensors)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATA PREPROCESSING                         â”‚
â”‚  â€¢ Parse timestamps (MM:SS.s format)                        â”‚
â”‚  â€¢ Resample to 1 Hz                                         â”‚
â”‚  â€¢ Interpolate gaps â‰¤3 seconds                              â”‚
â”‚  â€¢ Create 60s windows (15s stride)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               FEATURE EXTRACTION                            â”‚
â”‚  â€¢ Flow: mean, std, CV, zeros, rate_of_change              â”‚
â”‚  â€¢ Density: mean, std, trend, spikes, SG deviation         â”‚
â”‚  â€¢ Pressure: mean, variability, correlation with flow      â”‚
â”‚  â€¢ Physical validation (mass balance, density-SG)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            MultiROCKET CLASSIFIER (Local/Fast)              â”‚
â”‚  â€¢ Processes windows in milliseconds                        â”‚
â”‚  â€¢ Output: {fault_type, confidence}                         â”‚
â”‚  â€¢ 75% accuracy (demo quality)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MISTRAL-7B LLM EXPLAINER (Colab GPU)               â”‚
â”‚  â€¢ Input: classifier prediction + extracted features        â”‚
â”‚  â€¢ Self-consistency: Generate 5 explanations, vote          â”‚
â”‚  â€¢ Output: Structured JSON with evidence & actions          â”‚
â”‚  â€¢ ~90s per window (with k=5)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FINAL OUTPUT                             â”‚
â”‚  â€¢ Fault Diagnosis: "Dilution"                             â”‚
â”‚  â€¢ Confidence: 0.856                                        â”‚
â”‚  â€¢ Evidence: [3-5 numeric claims]                          â”‚
â”‚  â€¢ Recommended Actions: [2-3 specific steps]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## How to Use (Demo Workflow)

### 1. Run Classifier on New Data
```bash
conda activate rm

python training/train_rocket.py \
    --data data/raw/YOUR_DATA.csv \
    --config experiments/configs/baseline.yaml \
    --output_dir outputs/YOUR_EXPERIMENT
```

### 2. Export Predictions for LLM
```bash
python export_for_colab.py \
    --model outputs/YOUR_EXPERIMENT/model.pkl \
    --data data/raw/YOUR_DATA.csv \
    --output outputs/YOUR_EXPERIMENT/predictions_for_colab.parquet
```

### 3. (Optional) Filter to High-Confidence Faults
```bash
python filter_high_confidence_faults.py \
    --input outputs/YOUR_EXPERIMENT/predictions_for_colab.parquet \
    --output outputs/YOUR_EXPERIMENT/predictions_high_conf_faults.parquet \
    --threshold 0.7
```

### 4. Generate Explanations (Google Colab)
1. Upload `FD_LLM_Colab_Explainer.ipynb` to Colab
2. Upload predictions file to Google Drive
3. Select GPU runtime (T4/V100/A100)
4. Run all cells
5. Download `explanations.jsonl`

---

## Production Readiness Checklist

To upgrade this demo to a production system:

### Must-Have Improvements:
- [ ] **Retrain classifier to â‰¥90% accuracy**
  - Get representative training data (85-95% Normal operations)
  - Expert-validate labels (not heuristic-based)
  - Balance classes properly
  
- [ ] **Validate on multiple time periods**
  - Test on data from different dates/conditions
  - Ensure generalization

- [ ] **Reduce false positive rate**
  - Current: ~25% (based on 75% accuracy)
  - Target: <5%

### Nice-to-Have Improvements:
- [ ] Fine-tune LLM on domain-specific examples
- [ ] Add more fault types (blockage, cavitation, etc.)
- [ ] Real-time deployment infrastructure
- [ ] Operator feedback loop for continuous improvement
- [ ] Dashboard for monitoring and visualization

---

## Key Learnings & Insights

### What Worked Well:
âœ… **Hybrid architecture is sound** - combining fast classifier + LLM explainer  
âœ… **Self-consistency voting improves reliability** - majority vote reduces hallucinations  
âœ… **Mistral-7B follows JSON format well** - better than DeepSeek-R1 for structured output  
âœ… **Colab GPU integration** - cost-effective for LLM inference  
âœ… **Feature extraction is solid** - basic stats capture key patterns  

### What Needs Improvement:
âš ï¸ **Label quality is critical** - heuristic labels limit accuracy  
âš ï¸ **Representative data matters** - abnormal data (65% faults) hurts generalization  
âš ï¸ **LLM speed is a bottleneck** - 90s/window with k=5 is too slow for production  

### Design Decisions:
- **Why MultiROCKET?** Fast, robust baseline for time-series (no deep learning complexity)
- **Why Mistral over DeepSeek-R1?** Better at following JSON format (DeepSeek shows reasoning)
- **Why self-consistency?** LLMs can hallucinate; voting improves faithfulness
- **Why separate classifier + LLM?** Classifier is fast for real-time, LLM for explanation quality

---

## Demo Use Cases

### 1. Research & Development
- Demonstrate hybrid ML + LLM approach
- Benchmark different LLM models
- Test explanation quality metrics

### 2. Stakeholder Presentations
- Show end-to-end fault detection + explanation
- Demonstrate natural language interface
- Prove concept feasibility

### 3. Pilot Deployment
- Run on historical data to identify patterns
- Get operator feedback on explanation quality
- Inform production system requirements

---

## Repository Structure

```
fd-llm/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ loaders/           # CSV parsing, windowing
â”‚   â””â”€â”€ raw/               # Input CSV files
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ encoders/          # Feature extraction
â”‚   â”œâ”€â”€ rocket_heads.py    # MultiROCKET classifier
â”‚   â””â”€â”€ fusion.py          # Late fusion (optional)
â”œâ”€â”€ explainer/
â”‚   â”œâ”€â”€ llm_setup.py       # LLM loading (QLoRA)
â”‚   â”œâ”€â”€ prompt_templates.py # Prompts & validation
â”‚   â””â”€â”€ self_consistency.py # Voting mechanism
â”œâ”€â”€ training/
â”‚   â””â”€â”€ train_rocket.py    # Main training script
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ metrics.py         # Performance metrics
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ physical_checks.py # Mass balance validation
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ exp_full_dataset/  # Results & models
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ configs/           # YAML configurations
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ filter_*.py            # Utility scripts
â”œâ”€â”€ analyze_*.py           # Analysis scripts
â”œâ”€â”€ export_for_colab.py    # Prepare data for LLM
â”œâ”€â”€ FD_LLM_Colab_Explainer.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ DEMO_PROJECT_SUMMARY.md (this file)
```

---

## Contact & Next Steps

**For Production Deployment:**
1. Collect representative operational data
2. Expert-label a training set (500-1000 windows)
3. Retrain classifier to â‰¥90% accuracy
4. Fine-tune LLM on domain examples
5. Deploy with monitoring infrastructure

**For Research:**
- Experiment with different LLM models
- Test explanation faithfulness metrics
- Compare with other time-series classifiers
- Publish results on benchmark datasets

---

**This is a complete, functional demo that proves the hybrid fault detection + LLM explanation concept works. It's ready for demonstrations, research, and as a foundation for a production system.**

**Status:** âœ… Demo Complete | âš ï¸ Not Production-Ready (needs 90%+ accuracy)

